#!/usr/bin/env python3
"""
Google Sheets to sbdb Incremental Sync Script
êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„°ë¥¼ ì¦ë¶„ ì—…ë°ì´íŠ¸ë¡œ sbdbì— ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import gspread
from google.oauth2.service_account import Credentials
import subprocess
import json
import sys
import io
import hashlib
from datetime import datetime
from pathlib import Path

# Windows console UTF-8 encoding fix
if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except Exception:
        pass  # If it fails, continue with default encoding

# ì„¤ì • íŒŒì¼ ë¡œë“œ
def load_config():
    """config.json íŒŒì¼ì—ì„œ ì„¤ì • ì½ê¸°"""
    config_path = Path(__file__).parent / "config.json"

    if not config_path.exists():
        print("âŒ config.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ê²½ë¡œ: {config_path}")
        sys.exit(1)

    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# ë™ê¸°í™” ìƒíƒœ ë¡œë“œ
def load_sync_state():
    """sync_state.jsonì—ì„œ ì´ì „ ë™ê¸°í™” ìƒíƒœ ì½ê¸°"""
    state_path = Path(__file__).parent / "sync_state.json"

    if not state_path.exists():
        return {
            "last_sync": None,
            "synced_rows": {},
            "total_rows": 0
        }

    with open(state_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# ë™ê¸°í™” ìƒíƒœ ì €ì¥
def save_sync_state(state):
    """sync_state.jsonì— ë™ê¸°í™” ìƒíƒœ ì €ì¥"""
    state_path = Path(__file__).parent / "sync_state.json"

    with open(state_path, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

# í–‰ í•´ì‹œ ìƒì„± (ê³ ìœ  ID)
def generate_row_hash(row, headers):
    """í–‰ì˜ ê³ ìœ  ID ìƒì„± (ë¶€ì„œëª… + ìš©ì—­ëª…)"""
    # ì²« ë‘ ì»¬ëŸ¼(ë¶€ì„œëª…, ìš©ì—­ëª…)ìœ¼ë¡œ ê³ ìœ  ID ìƒì„±
    if len(headers) >= 2:
        key = f"{row.get(headers[0], '')}-{row.get(headers[1], '')}"
    else:
        # ëª¨ë“  ê°’ì„ ê²°í•©
        key = "-".join(str(v) for v in row.values())

    return hashlib.md5(key.encode('utf-8')).hexdigest()

# ì²´í¬ì„¬ ìƒì„± (ë‚´ìš© ë³€ê²½ ê°ì§€)
def generate_checksum(row):
    """í–‰ ë‚´ìš©ì˜ ì²´í¬ì„¬ ìƒì„±"""
    content = json.dumps(row, sort_keys=True, ensure_ascii=False)
    return hashlib.md5(content.encode('utf-8')).hexdigest()

# êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
def connect_to_sheet(config):
    """Service Accountë¡œ êµ¬ê¸€ ì‹œíŠ¸ì— ì—°ê²°"""
    service_account_file = Path(__file__).parent / config['service_account_file']

    if not service_account_file.exists():
        print(f"âŒ Service Account JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ê²½ë¡œ: {service_account_file}")
        sys.exit(1)

    scopes = [
        'https://www.googleapis.com/auth/spreadsheets.readonly',
        'https://www.googleapis.com/auth/drive.readonly'
    ]

    try:
        creds = Credentials.from_service_account_file(
            str(service_account_file),
            scopes=scopes
        )

        client = gspread.authorize(creds)
        spreadsheet = client.open_by_key(config['sheet_id'])

        if 'gid' in config and config['gid']:
            for worksheet in spreadsheet.worksheets():
                if str(worksheet.id) == str(config['gid']):
                    return worksheet
            print(f"âš ï¸  GID {config['gid']}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ ì²« ë²ˆì§¸ ì‹œíŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

        return spreadsheet.sheet1

    except Exception as e:
        print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)

# ë°ì´í„° ì¶”ì¶œ
def fetch_sheet_data(worksheet):
    """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    try:
        all_values = worksheet.get_all_values()

        if not all_values or len(all_values) < 3:
            print("âš ï¸  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return [], []

        # ë‘ ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
        raw_headers = all_values[1]

        # ë¹ˆ í—¤ë” ì²˜ë¦¬
        headers = []
        header_indices = []
        seen = set()

        for idx, header in enumerate(raw_headers):
            if not header or header.strip() == '':
                continue

            original_header = header.strip()
            unique_header = original_header
            counter = 1
            while unique_header in seen:
                unique_header = f"{original_header}_{counter}"
                counter += 1

            headers.append(unique_header)
            header_indices.append(idx)
            seen.add(unique_header)

        # ë°ì´í„° í–‰ ë³€í™˜
        all_records = []
        for row in all_values[2:]:
            if not any(cell.strip() for cell in row if cell):
                continue

            record = {}
            for header, idx in zip(headers, header_indices):
                if idx < len(row):
                    record[header] = row[idx]
                else:
                    record[header] = ""

            # ìš©ì—­ëª…(ë‘ ë²ˆì§¸ ì»¬ëŸ¼)ì´ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            if len(headers) > 1:
                project_name = record.get(headers[1], "").strip()
                if not project_name:
                    continue

            all_records.append(record)

        print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(all_records)}ê°œ í–‰")
        print(f"ğŸ“‹ ì»¬ëŸ¼ ({len(headers)}ê°œ): {', '.join(headers[:5])}" +
              (f", ..." if len(headers) > 5 else ""))

        return all_records, headers

    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

# ë³€ê²½ ì‚¬í•­ ê°ì§€
def detect_changes(current_data, headers, sync_state):
    """í˜„ì¬ ë°ì´í„°ì™€ ì´ì „ ìƒíƒœ ë¹„êµí•˜ì—¬ ë³€ê²½ ì‚¬í•­ ê°ì§€"""
    changes = {
        'new': [],       # ìƒˆë¡œ ì¶”ê°€ëœ í–‰
        'updated': [],   # ë‚´ìš©ì´ ë³€ê²½ëœ í–‰
        'deleted': [],   # ì‚­ì œëœ í–‰
        'unchanged': 0   # ë³€ê²½ ì—†ëŠ” í–‰
    }

    current_hashes = set()

    for idx, row in enumerate(current_data):
        row_hash = generate_row_hash(row, headers)
        checksum = generate_checksum(row)
        current_hashes.add(row_hash)

        if row_hash not in sync_state['synced_rows']:
            # ìƒˆ í–‰
            changes['new'].append({
                'index': idx + 1,
                'hash': row_hash,
                'checksum': checksum,
                'data': row
            })
        else:
            # ê¸°ì¡´ í–‰ - ë‚´ìš© ë³€ê²½ í™•ì¸
            old_checksum = sync_state['synced_rows'][row_hash]['checksum']
            if checksum != old_checksum:
                changes['updated'].append({
                    'index': idx + 1,
                    'hash': row_hash,
                    'checksum': checksum,
                    'data': row,
                    'doc_id': sync_state['synced_rows'][row_hash]['doc_id']
                })
            else:
                changes['unchanged'] += 1

    # ì‚­ì œëœ í–‰ ê°ì§€
    for old_hash, old_data in sync_state['synced_rows'].items():
        if old_hash not in current_hashes:
            changes['deleted'].append({
                'hash': old_hash,
                'title': old_data['title'],
                'doc_id': old_data['doc_id']
            })

    return changes

# sbdbì— ë¬¸ì„œ ì €ì¥
def save_to_sbdb(row_data, headers, config, index):
    """í•œ í–‰ì˜ ë°ì´í„°ë¥¼ sbdbì— ì €ì¥"""
    # ë¶€ì„œëª… (ì²« ë²ˆì§¸ ì»¬ëŸ¼)
    department = row_data.get(headers[0], "").strip() if len(headers) > 0 else ""
    # ìš©ì—­ëª… (ë‘ ë²ˆì§¸ ì»¬ëŸ¼)
    project_name = row_data.get(headers[1], "").strip() if len(headers) > 1 else ""

    # íƒ€ì´í‹€ ìƒì„±: [ì…ì°°ì°¸ì—¬] ì¹´í…Œê³ ë¦¬ + ë¶€ì„œëª… + ìš©ì—­ëª… (50ì ì œí•œ)
    if department and project_name:
        title_base = f"{department} - {project_name}"
    elif department:
        title_base = department
    elif project_name:
        title_base = project_name
    else:
        title_base = "ì…ì°°ì •ë³´"

    # ìš©ì—­ëª…ì´ ë„ˆë¬´ ê¸¸ë©´ 50ìë¡œ ìë¥´ê¸°
    if len(title_base) > 50:
        title_base = title_base[:47] + "..."

    title = f"[ì…ì°°ì°¸ì—¬] {title_base} (#{index})"

    content_lines = [f"# {title}", ""]

    for header in headers:
        value = row_data.get(header, "")
        if value != "" and value is not None:
            content_lines.append(f"- **{header}**: {value}")

    content = "\n".join(content_lines)

    today = datetime.now().strftime("%Y.%m.%d")
    tags = config.get('tags', []) + [today, "ì…ì°°ì°¸ì—¬"]
    tags_str = ",".join(tags)

    sbdb_script = r"C:\Users\hjj\.claude\skills\sbdb\scripts\save_document.py"

    cmd = [
        "python",
        sbdb_script,
        "--content", content,
        "--title", title,
        "--tags", tags_str,
        "--db-name", config.get('sbdb_db_name', 'company'),
        "--type", "text"
    ]

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8'
        )

        if result.returncode == 0:
            # ë¬¸ì„œ ID ì¶”ì¶œ (ì¶œë ¥ì—ì„œ)
            doc_id = extract_doc_id(result.stdout)
            return True, doc_id, None
        else:
            return False, None, result.stderr

    except Exception as e:
        return False, None, str(e)

# sbdb ë¬¸ì„œ ì—…ë°ì´íŠ¸
def update_sbdb_document(doc_id, row_data, headers, config, index):
    """sbdbì˜ ê¸°ì¡´ ë¬¸ì„œ ì—…ë°ì´íŠ¸"""
    # ë¶€ì„œëª… (ì²« ë²ˆì§¸ ì»¬ëŸ¼)
    department = row_data.get(headers[0], "").strip() if len(headers) > 0 else ""
    # ìš©ì—­ëª… (ë‘ ë²ˆì§¸ ì»¬ëŸ¼)
    project_name = row_data.get(headers[1], "").strip() if len(headers) > 1 else ""

    # íƒ€ì´í‹€ ìƒì„±: [ì…ì°°ì°¸ì—¬] ì¹´í…Œê³ ë¦¬ + ë¶€ì„œëª… + ìš©ì—­ëª… (50ì ì œí•œ)
    if department and project_name:
        title_base = f"{department} - {project_name}"
    elif department:
        title_base = department
    elif project_name:
        title_base = project_name
    else:
        title_base = "ì…ì°°ì •ë³´"

    # ìš©ì—­ëª…ì´ ë„ˆë¬´ ê¸¸ë©´ 50ìë¡œ ìë¥´ê¸°
    if len(title_base) > 50:
        title_base = title_base[:47] + "..."

    title = f"[ì…ì°°ì°¸ì—¬] {title_base} (#{index})"

    content_lines = [f"# {title}", ""]

    for header in headers:
        value = row_data.get(header, "")
        if value != "" and value is not None:
            content_lines.append(f"- **{header}**: {value}")

    content = "\n".join(content_lines)

    sbdb_script = r"C:\Users\hjj\.claude\skills\sbdb\scripts\update_document.py"

    cmd = [
        "python",
        sbdb_script,
        doc_id,
        "--content", content,
        "--title", title,
        "--regenerate-embedding"
    ]

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8'
        )

        return result.returncode == 0, result.stderr if result.returncode != 0 else None

    except Exception as e:
        return False, str(e)

# sbdb ë¬¸ì„œ ì‚­ì œ
def delete_sbdb_document(doc_id):
    """sbdbì—ì„œ ë¬¸ì„œ ì‚­ì œ"""
    sbdb_script = r"C:\Users\hjj\.claude\skills\sbdb\scripts\delete_document.py"

    cmd = [
        "python",
        sbdb_script,
        doc_id,
        "--confirm"
    ]

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            encoding='utf-8'
        )

        return result.returncode == 0

    except Exception as e:
        return False

# ë¬¸ì„œ ID ì¶”ì¶œ
def extract_doc_id(output):
    """save_document.py ì¶œë ¥ì—ì„œ ë¬¸ì„œ ID ì¶”ì¶œ"""
    import re
    match = re.search(r'ID:\s*([a-f0-9-]+)', output)
    if match:
        return match.group(1)
    return None

# ë©”ì¸ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ”„ Google Sheets â†’ sbdb ì¦ë¶„ ë™ê¸°í™”")
    print("=" * 60)

    # ì„¤ì • ë¡œë“œ
    print("\nğŸ“ ì„¤ì • íŒŒì¼ ë¡œë“œ ì¤‘...")
    config = load_config()
    print(f"   ì‹œíŠ¸ ID: {config['sheet_id']}")
    print(f"   DB ì´ë¦„: {config.get('sbdb_db_name', 'company')}")

    # ë™ê¸°í™” ìƒíƒœ ë¡œë“œ
    print("\nğŸ“‚ ì´ì „ ë™ê¸°í™” ìƒíƒœ ë¡œë“œ ì¤‘...")
    sync_state = load_sync_state()

    if sync_state['last_sync']:
        last_sync_time = datetime.fromisoformat(sync_state['last_sync'])
        time_diff = datetime.now() - last_sync_time
        hours = int(time_diff.total_seconds() / 3600)
        minutes = int((time_diff.total_seconds() % 3600) / 60)

        print(f"   ë§ˆì§€ë§‰ ë™ê¸°í™”: {sync_state['last_sync']}")
        print(f"   ê²½ê³¼ ì‹œê°„: {hours}ì‹œê°„ {minutes}ë¶„ ì „")
        print(f"   ì´ì „ í–‰ ìˆ˜: {sync_state['total_rows']}ê°œ")
    else:
        print("   âœ¨ ì²« ë™ê¸°í™”ì…ë‹ˆë‹¤!")

    # êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
    print("\nğŸ”— êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì¤‘...")
    worksheet = connect_to_sheet(config)
    print(f"   ì‹œíŠ¸ ì´ë¦„: {worksheet.title}")

    # ë°ì´í„° ì¶”ì¶œ
    print("\nğŸ“¥ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
    current_data, headers = fetch_sheet_data(worksheet)

    if not current_data:
        print("âš ï¸  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë³€ê²½ ì‚¬í•­ ê°ì§€
    print("\nğŸ” ë³€ê²½ ì‚¬í•­ ê°ì§€ ì¤‘...")
    changes = detect_changes(current_data, headers, sync_state)

    print(f"   âœ¨ ìƒˆ í–‰: {len(changes['new'])}ê°œ")
    print(f"   ğŸ”„ ìˆ˜ì •ëœ í–‰: {len(changes['updated'])}ê°œ")
    print(f"   ğŸ—‘ï¸ ì‚­ì œëœ í–‰: {len(changes['deleted'])}ê°œ")
    print(f"   â­ï¸ ë³€ê²½ ì—†ìŒ: {changes['unchanged']}ê°œ")

    total_changes = len(changes['new']) + len(changes['updated']) + len(changes['deleted'])

    if total_changes == 0:
        print("\nâœ… ë³€ê²½ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ë™ê¸°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    # ë³€ê²½ ì‚¬í•­ ì²˜ë¦¬
    print(f"\nğŸ’¾ ë³€ê²½ ì‚¬í•­ ì²˜ë¦¬ ì¤‘... (ì´ {total_changes}ê°œ)")

    success_count = 0
    fail_count = 0
    processed = 0

    # ìƒˆ í–‰ ì¶”ê°€
    for item in changes['new']:
        processed += 1
        success, doc_id, error = save_to_sbdb(item['data'], headers, config, item['index'])

        if success and doc_id:
            success_count += 1
            title_field = headers[0] if headers else "í•­ëª©"
            title = f"{item['data'].get(title_field, 'í•­ëª©')} - #{item['index']}"

            # ìƒíƒœ ì—…ë°ì´íŠ¸
            sync_state['synced_rows'][item['hash']] = {
                'row_number': item['index'],
                'title': title,
                'doc_id': doc_id,
                'checksum': item['checksum']
            }

            print(f"   âœ… [{processed}/{total_changes}] ìƒˆ í–‰ ì¶”ê°€: {title[:50]}...")
        else:
            fail_count += 1
            print(f"   âŒ [{processed}/{total_changes}] ì¶”ê°€ ì‹¤íŒ¨: {error}")

    # ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸
    for item in changes['updated']:
        processed += 1
        success, error = update_sbdb_document(item['doc_id'], item['data'], headers, config, item['index'])

        if success:
            success_count += 1
            title_field = headers[0] if headers else "í•­ëª©"
            title = f"{item['data'].get(title_field, 'í•­ëª©')} - #{item['index']}"

            # ìƒíƒœ ì—…ë°ì´íŠ¸
            sync_state['synced_rows'][item['hash']]['checksum'] = item['checksum']
            sync_state['synced_rows'][item['hash']]['title'] = title

            print(f"   ğŸ”„ [{processed}/{total_changes}] ì—…ë°ì´íŠ¸: {title[:50]}...")
        else:
            fail_count += 1
            print(f"   âŒ [{processed}/{total_changes}] ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {error}")

    # ì‚­ì œëœ í–‰ ì œê±°
    for item in changes['deleted']:
        processed += 1
        success = delete_sbdb_document(item['doc_id'])

        if success:
            success_count += 1
            del sync_state['synced_rows'][item['hash']]
            print(f"   ğŸ—‘ï¸ [{processed}/{total_changes}] ì‚­ì œ: {item['title'][:50]}...")
        else:
            fail_count += 1
            print(f"   âŒ [{processed}/{total_changes}] ì‚­ì œ ì‹¤íŒ¨")

    # ë™ê¸°í™” ìƒíƒœ ì €ì¥
    sync_state['last_sync'] = datetime.now().isoformat()
    sync_state['total_rows'] = len(current_data)
    save_sync_state(sync_state)

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ì¦ë¶„ ë™ê¸°í™” ì™„ë£Œ")
    print("=" * 60)
    print(f"   âœ¨ ì¶”ê°€: {len(changes['new'])}ê°œ")
    print(f"   ğŸ”„ ìˆ˜ì •: {len(changes['updated'])}ê°œ")
    print(f"   ğŸ—‘ï¸ ì‚­ì œ: {len(changes['deleted'])}ê°œ")
    print(f"   â­ï¸ ê±´ë„ˆë›°ê¸°: {changes['unchanged']}ê°œ")
    print(f"   âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"   âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
    print("=" * 60)

if __name__ == "__main__":
    main()
